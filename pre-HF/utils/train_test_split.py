# Take full tokenized data and do train/text split on it

